# ðŸ“š Final Project: Data Science & Machine Learning (INDE 577)

This repository presents my final project for **CMOR 438/INDE 577: Data Science & Machine Learning** at Rice University, completed under the supervision of **Dr. Randy R. Davila**.  
In this project, I implemented key supervised and unsupervised machine learning algorithms entirely from scratch, applying them to original and carefully selected datasets to simulate real-world applications.
Each section includes full code, analysis, visualizations, and documentation, reflecting my understanding of both fundamental concepts and practical modeling techniques.

## What This Project Includes:
- Implementation of important algorithms for **supervised** and **unsupervised** learning.
- Application of models to unique or self-created datasets (not reusing lecture datasets).
- Clear visualizations such as decision boundaries, scatter plots, and learning curves.
- Detailed result analysis and discussion for each model.

## Course Information:
- **Course Name:** Data Science and Machine Learning (CMOR 438/INDE 577)
- **University:** Rice University
- **Instructor:** Dr. Randy R. Davila  
- **Semester:** Fall 2024

This course introduced core concepts of machine learning, covering topics like regression models, clustering methods, decision trees, neural networks, and ensemble techniques.

## Tools and Libraries Used:
- Python 3.8
- Libraries:  
  - **NumPy**  
  - **Pandas**  
  - **Matplotlib**  
  - **Seaborn**  
  - **scikit-learn**

## Overview

This repository contains implementations of key supervised and unsupervised machine learning algorithms from scratch.

## ðŸ§  Supervised Learning

- [Perceptron](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Perceptron)
- [Linear Regression](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Linear%20Regression)
- [Logistic Regression](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Logistic%20Regression)
- [Neural Network](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Neural%20Network)
- [K Nearest Neighbors (KNN)](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/KNN)
- [Decision Tree](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Decision%20Tree)
- [Random Forests](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Random%20Forests)
- [Ensemble Learning](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Supervised_Learning/Ensemble%20Learning)

## ðŸ“Š Unsupervised Learning

- [K-Means Clustering](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Unupervised_Learning/K-Means%20Clustering)
- [DBSCAN](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Unupervised_Learning/DBSCAN)
- [Principal Component Analysis (PCA)](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Unupervised_Learning/%20Principal%20Component%20Analysis)
- [Image Compression with Singular Value Decomposition (SVD)](https://github.com/beyzaispiir/ML_Algorithms_From_Scratch/tree/main/Unupervised_Learning/Image%20Compression%20with%20the%20Singular%20Value%20Decomposition%20(SVD))

---

âœ… Each folder contains:
- Full code implementations from scratch
- Dataset summaries
- Visualizations (plots, decision boundaries, learning curves)
- Results and analysis
- README.md files explaining algorithms and usage

---


## Instructions for Reproducing Results

1. Clone the repository:
    ```bash
    git clone <your-repository-link>
    ```

2. Navigate to the desired algorithm's folder:
    ```bash
    cd Supervised_Learning/Perceptron
    ```

3. Open the Jupyter Notebook (`.ipynb`) file and run all cells sequentially.

4. Install required libraries if needed:
    ```bash
    pip install numpy pandas matplotlib seaborn scikit-learn
    ```

5. Follow instructions in each notebook to visualize results.

---

## âœ¨ Project Highlights
- All models implemented from scratch (no `sklearn` high-level functions used for model building unless otherwise allowed).
- Custom datasets prepared to avoid overlap with lecture datasets.
- Clear visualizations (scatter plots, decision boundaries, learning curves).
- Detailed residual analysis and result interpretation for each model.

---

## Notes
- README.md files included for each subfolder with description, dataset summary, and reproduction steps.
- Visualizations are carefully designed to support analysis (required for full credit).
- Documentation is complete and clear following the final project rubric.

---
## Instructor Contact:
- Dr. Randy R. Davila
- Department of Computational and Applied Mathematics
- Rice University, Houston, TX 77005
- Email: [rrd6@rice.edu]
---
## ðŸ“œ Acknowledgments

Special thanks to **Dr. Randy R. Davila** for providing clear guidance and project objectives throughout the course.  
The recommendations from **Towards Data Science** and the course material were instrumental in helping me successfully complete this project.

---

