# ðŸ“š Final Project: Data Science & Machine Learning (CMOR 438/INDE 577)

## Overview

This repository contains my final project for CMOR 438/INDE 577: Data Science & Machine Learning.  
It demonstrates my understanding of supervised and unsupervised learning algorithms, following the project requirements.

The repository includes two main directories:
- **Supervised_Learning/**
- **Unsupervised_Learning/**

Each algorithm includes:
- Full implementation (mostly from scratch)
- Use of a different dataset from lecture examples
- Visualizations and analysis
- A README.md in each folder

## Directory Structure
â”œâ”€â”€ Supervised_Learning
â”‚   â”œâ”€â”€ Perceptron
â”‚   â”œâ”€â”€ Logistic_Regression
â”‚   â””â”€â”€ (other supervised learning algorithms)
â”œâ”€â”€ Unsupervised_Learning
â”‚   â”œâ”€â”€ KMeans
â”‚   â””â”€â”€ (other unsupervised learning algorithms)
â””â”€â”€ README.md


## Implemented Algorithms

### Supervised Learning
- Perceptron
- Logistic Regression
- (to be completed: Linear Regression, Neural Networks, Decision Trees, etc.)

### Unsupervised Learning
- (to be completed: KMeans Clustering, DBSCAN, PCA, SVD)

## Dataset Summary

- **Perceptron**: A manually created dataset based on customers' annual income and spending score, predicting purchase behavior (binary classification).
- **Logistic Regression**: A synthetic dataset created manually with two continuous features (X1, X2) and a binary target.

Datasets were created manually or selected carefully to be different from lecture examples.

## Instructions for Reproducing Results

1. Clone the repository:
    ```bash
    git clone <your-repository-link>
    ```

2. Navigate to the desired algorithm's folder:
    ```bash
    cd Supervised_Learning/Perceptron
    ```

3. Open the Jupyter Notebook (`.ipynb`) file and run all cells sequentially.

4. Install required libraries if needed:
    ```bash
    pip install numpy pandas matplotlib seaborn scikit-learn
    ```

5. Follow instructions in each notebook to visualize results.

---

## âœ¨ Project Highlights
- All models implemented from scratch (no `sklearn` high-level functions used for model building unless otherwise allowed).
- Custom datasets prepared to avoid overlap with lecture datasets.
- Clear visualizations (scatter plots, decision boundaries, learning curves).
- Detailed residual analysis and result interpretation for each model.

---

## Notes
- README.md files included for each subfolder with description, dataset summary, and reproduction steps.
- Visualizations are carefully designed to support analysis (required for full credit).
- Documentation is complete and clear following the final project rubric.

---
