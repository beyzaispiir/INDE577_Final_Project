# ðŸ“š Final Project: Data Science & Machine Learning (INDE 577)

## Overview

This repository contains my final project for CMOR 438/INDE 577: Data Science & Machine Learning.  
It demonstrates my understanding of supervised and unsupervised learning algorithms, following the project requirements.

The repository includes two main directories:
- **Supervised_Learning/**
- **Unsupervised_Learning/**

Each algorithm includes:
- Full implementation (mostly from scratch)
- Use of a different dataset from lecture examples
- Visualizations and analysis
- A README.md in each folder
- 
## ðŸ“‚ Directory Structure

- `Supervised_Learning/`
  - `Perceptron/`
  - `Linear Regression/`
  - `Logistic Regression/`
  - `Neural Network/`
  - `KNN/`
  - `Decision Tree/`
  - `Random Forests/`
  - `Ensemble Learning/`
- `Unsupervised_Learning/`
  - `K-Means Clustering/`
  - `DBSCAN/`
  - `Principal Component Analysis/`
  - `Image Compression with the Singular Value Decomposition (SVD)/`

Each folder contains:
- Jupyter Notebook files with full implementation and results
- Visualizations (plots, learning curves, decision boundaries)
- A `README.md` specific to each algorithm (brief description, dataset summary, reproduction steps)

---

## ðŸ“š Implemented Algorithms

### Supervised Learning
- Perceptron
- Linear Regression
- Logistic Regression
- Neural Networks (basic feedforward)
- K-Nearest Neighbors (KNN)
- Decision Trees
- Random Forests
- Other Ensemble Methods (Boosting)

### Unsupervised Learning
- K-Means Clustering
- DBSCAN
- Principal Component Analysis (PCA)
- Image Compression using SVD

## Instructions for Reproducing Results

1. Clone the repository:
    ```bash
    git clone <your-repository-link>
    ```

2. Navigate to the desired algorithm's folder:
    ```bash
    cd Supervised_Learning/Perceptron
    ```

3. Open the Jupyter Notebook (`.ipynb`) file and run all cells sequentially.

4. Install required libraries if needed:
    ```bash
    pip install numpy pandas matplotlib seaborn scikit-learn
    ```

5. Follow instructions in each notebook to visualize results.

---

## âœ¨ Project Highlights
- All models implemented from scratch (no `sklearn` high-level functions used for model building unless otherwise allowed).
- Custom datasets prepared to avoid overlap with lecture datasets.
- Clear visualizations (scatter plots, decision boundaries, learning curves).
- Detailed residual analysis and result interpretation for each model.

---

## Notes
- README.md files included for each subfolder with description, dataset summary, and reproduction steps.
- Visualizations are carefully designed to support analysis (required for full credit).
- Documentation is complete and clear following the final project rubric.

---
